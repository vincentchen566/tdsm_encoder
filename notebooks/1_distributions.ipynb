{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707b7fb0",
   "metadata": {},
   "source": [
    "## Plot data distribution\n",
    "\n",
    "Display distributions of either the transformed or non-transformed input features. This is one way of inspecting how the transformation is affecting the distributions input to the training. Transforming data is an important part of the pre-processing stage of machine learning projects. We want to ensure that the input features have distributions that are as easy as possible for the machine learning algorithm to learn and that features have a similar numerical range, to avoid the task of loss minimisation shifting focus to a single variable. One commonly used way of doing this is to transform variables to have a Gaussian like distribution. In order to choose the transformation function that is best for your data, it is important to study the data and how the transformation affects your distributions. Note that pre-processing data can be one of the most time consuming aspects of a machine learning project and can have a profound affect on the success of the project, so take your time here.\n",
    "\n",
    "Training is always performed using the transformed inputs where available. The `energy_trans_file` argument should be the pickle file containing fitted input transformation function. Only provide a file name if you want to plot distributions where the transformation has been inverted and applied to inputs to transform back to the original distributions. In such cases, if you want to check the inverted transformation is doing the correct inversion, compare for a single file against the plots inside the directory:\n",
    "\n",
    "`\n",
    "datasets/<transformation>/featureplots_dataset\n",
    "`\n",
    "\n",
    "Plots of the inverted transformation should be similar to what is shown in those, though not identical as we only plot a subset of the showers.\n",
    "\n",
    "#### Choice of transformation\n",
    "What we don't want in our dataset:\n",
    "\n",
    "1. Negative values are currently problematic given the loss function and subsequent diffusion paradigm we have chosen. The precise mathematical reasoning need to be ironed out, however it leads to a runaway effect when generating showers that produces more and more negative values.\n",
    "\n",
    "2. Due to point 1, our padding value is set to zero and hence we don't want a distribution for the features that includes zero.\n",
    "\n",
    "The dataset contains a wide range of hit energies that has a few outliers with incredibly high energy so we need a transformation for hit energy that is robust to outliers. Hence, I have tried to use the quantile transformation to uniform distribution and put an offset of '+1' to avoid zero (padding) values. MinMax works to some degree, but due to the extremely high valued energy outliers, when we extract the values from the distribution for the transformation, the outliers skew everything, rendering some of the small hit energy values extremely small, hence they are all very close to the lower bound of the distribution. This might make their distribution difficult for the model to learn, as they are all very close together for e.g. the bucket with 1 to 30 hits.\n",
    "\n",
    "The X and Y position distributions don't have such extreme outliers so we don't need the robustness to outliers in the transformation. When using e.g. quantile transformation to uniform however, the zero values in the Y position create a huge peak and the absence of such values in the X create a discontinuity in the X position distribution. Transforming to a quantile gaussian creates quite a wide distribution with negative values so ofsetting this to be positive would require some fine-tuning of the offset that is a bit fiddly. So for the X and Y I have chosen the to use a minmax transformation, setting the range to (1,2) to avoid padding values.\n",
    "\n",
    "### Transformations\n",
    "\n",
    "#### Quantile gaussian transformation:\n",
    "Non-linear transformation that maps the probability density function of each feature to a gaussian distribution, including outliers. Lower numbers become smaller and eventually negative.\n",
    "\n",
    "#### Quantile uniform transformation:\n",
    "Non-linear transformation that maps the probability density function of each feature to a uniform distribution, including outliers. Lower numbers become smaller and eventually negative.\n",
    "\n",
    "#### Power transformation:\n",
    "Stabilises against variance and skew by applying a power transformation to each variable to make them more gaussian-like.\n",
    "\n",
    "#### MinMax transformation:\n",
    "Transforms all data to predetermined range. The default range will be between 0-1.\n",
    "```\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbda740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:  ./\n",
      "[]\n",
      "# showers to plot: 1000\n",
      "plot_distribution running on input type 'files'\n",
      "# files: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(files_list_)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Transformed variables\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m dists_trans \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles_list_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnshowers_2_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m entries \u001b[38;5;241m=\u001b[39m dists_trans[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m all_incident_e_trans \u001b[38;5;241m=\u001b[39m dists_trans[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\vince\\tdsm_encoder\\notebooks\\..\\util\\display.py:147\u001b[0m, in \u001b[0;36mplot_distribution\u001b[1;34m(files_, nshowers_2_plot, padding_value, batch_size, energy_trans, masking)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m nshowers_per_file \u001b[38;5;241m=\u001b[39m [nshowers_2_plot\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mn_files \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_files)]\n\u001b[1;32m--> 147\u001b[0m r_ \u001b[38;5;241m=\u001b[39m nshowers_2_plot \u001b[38;5;241m%\u001b[39m \u001b[43mnshowers_per_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    148\u001b[0m nshowers_per_file[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m nshowers_per_file[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mr_\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# showers per file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnshowers_per_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time, functools, torch, os,sys, random, fnmatch, psutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "sys.path.insert(1, '../')\n",
    "import utils\n",
    "import util.display\n",
    "\n",
    "dataset = \"dataset_2_padded_nentry\"\n",
    "preproc_dataset_name = 'ds2_diff_transforms'\n",
    "dataset_store_path = os.path.join(\"/Users/vince/tdsm_encoder/datasets/\", preproc_dataset_name)\n",
    "jupyternotebook = True\n",
    "workingdir = \"./\"\n",
    "padding_value = 0.0\n",
    "\n",
    "print('Working directory: ', workingdir)\n",
    "\n",
    "# Input files\n",
    "files_list_ = []\n",
    "for filename in os.listdir(dataset_store_path):\n",
    "    if fnmatch.fnmatch(filename, dataset + '*424To564.pt'):\n",
    "        files_list_.append(os.path.join(dataset_store_path, filename))\n",
    "print(files_list_)\n",
    "\n",
    "# Transformed variables\n",
    "dists_trans = util.display.plot_distribution(files_list_, nshowers_2_plot=1000, padding_value=padding_value)\n",
    "entries = dists_trans[0]\n",
    "all_incident_e_trans = dists_trans[1]\n",
    "total_deposited_e_shower_trans = dists_trans[2]\n",
    "all_e_trans = dists_trans[3]\n",
    "all_x_trans = dists_trans[4]\n",
    "all_y_trans = dists_trans[5]\n",
    "all_z_trans = dists_trans[6]\n",
    "all_hit_ine_trans = dists_trans[7]\n",
    "average_x_shower_trans = dists_trans[8]\n",
    "average_y_shower_trans = dists_trans[9]\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(12,12))\n",
    "fig.suptitle('Transformed', fontsize=16)\n",
    "print('Plot # entries')\n",
    "ax[0][0].set_ylabel('# entries')\n",
    "ax[0][0].set_xlabel('Hit entries')\n",
    "ax[0][0].hist(entries, 50, color='orange', label='Geant4')\n",
    "ax[0][0].legend(loc='upper right')\n",
    "\n",
    "print('Plot hit energies')\n",
    "ax[0][1].set_ylabel('# entries')\n",
    "ax[0][1].set_xlabel('Hit energy [GeV]')\n",
    "ax[0][1].hist(all_e_trans, 50, color='orange', label='Geant4')\n",
    "ax[0][1].set_yscale('log')\n",
    "ax[0][1].legend(loc='upper right')\n",
    "\n",
    "print('Plot hit x')\n",
    "ax[0][2].set_ylabel('# entries')\n",
    "ax[0][2].set_xlabel('Hit x position')\n",
    "ax[0][2].hist(all_x_trans, 50, color='orange', label='Geant4')\n",
    "ax[0][2].set_yscale('log')\n",
    "ax[0][2].legend(loc='upper right')\n",
    "\n",
    "print('Plot hit y')\n",
    "ax[1][0].set_ylabel('# entries')\n",
    "ax[1][0].set_xlabel('Hit y position')\n",
    "ax[1][0].hist(all_y_trans, 50, color='orange', label='Geant4')\n",
    "ax[1][0].set_yscale('log')\n",
    "ax[1][0].legend(loc='upper right')\n",
    "\n",
    "print('Plot hit z')\n",
    "ax[1][1].set_ylabel('# entries')\n",
    "ax[1][1].set_xlabel('Hit z position')\n",
    "ax[1][1].hist(all_z_trans, color='orange', label='Geant4')\n",
    "ax[1][1].set_yscale('log')\n",
    "ax[1][1].legend(loc='upper right')\n",
    "\n",
    "print('Plot incident energies')\n",
    "ax[1][2].set_ylabel('# entries')\n",
    "ax[1][2].set_xlabel('Incident energies [GeV]')\n",
    "ax[1][2].hist(all_incident_e_trans, 50, color='orange', label='Geant4')\n",
    "ax[1][2].set_yscale('log')\n",
    "ax[1][2].legend(loc='upper right')\n",
    "\n",
    "print('Plot total deposited hit energy per shower')\n",
    "ax[2][0].set_ylabel('# entries')\n",
    "ax[2][0].set_xlabel('Deposited energy [GeV]')\n",
    "ax[2][0].hist(total_deposited_e_shower_trans, 50, color='orange', label='Geant4')\n",
    "ax[2][0].set_yscale('log')\n",
    "ax[2][0].legend(loc='upper right')\n",
    "\n",
    "print('Plot av. X position per shower')\n",
    "ax[2][1].set_ylabel('# entries')\n",
    "ax[2][1].set_xlabel('Average X position [GeV]')\n",
    "ax[2][1].hist(average_x_shower_trans, 50, color='orange', label='Geant4')\n",
    "ax[2][1].set_yscale('log')\n",
    "ax[2][1].legend(loc='upper right')\n",
    "\n",
    "print('Plot av. Y position per shower')\n",
    "ax[2][2].set_ylabel('# entries')\n",
    "ax[2][2].set_xlabel('Average Y position [GeV]')\n",
    "ax[2][2].hist(average_y_shower_trans, 50, color='orange', label='Geant4')\n",
    "ax[2][2].set_yscale('log')\n",
    "ax[2][2].legend(loc='upper right')\n",
    "\n",
    "save_name = os.path.join(dataset_store_path,'input_dists_transformed.png')\n",
    "print(f'save to: {save_name}')\n",
    "fig.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfac13",
   "metadata": {},
   "source": [
    "## 2D distributions\n",
    "Now we can look at tsome of the 2D correlation plots between features we want to generate, as well as the conditional incident energy. We can also see the 1D PDF (plotted in the cells above) along the x/y-axis. The z-axis always shows the incident energy. We compare non-transformed with transformed variables. Note that this cell depends on variables set in the cell above e.g. to change the number of showers ghenerated for the Transformed examples, you need to change the number of showers to plot in the cell above and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-transformed variables\n",
    "\n",
    "distributions = [(('X', 'Hit energy [GeV]', 'Incident energy [GeV]') , (all_x, all_e, all_hit_ine, all_x_trans, all_e_trans, all_hit_ine_trans))]\n",
    "util.display.make_plot(distributions)\n",
    "\n",
    "distributions = [(('Hit energy [GeV]', 'Incident energy [GeV]', 'Incident energy [GeV]') , (all_e, all_hit_ine, all_hit_ine, all_e_trans, all_hit_ine_trans, all_hit_ine_trans))]\n",
    "util.display.make_plot(distributions)\n",
    "\n",
    "distributions = [(('entries', 'Av. Energy Deposited [GeV]', 'Incident energy [GeV]') , (entries, total_deposited_e_shower, all_incident_e, entries, total_deposited_e_shower_trans, all_incident_e_trans))]\n",
    "util.display.make_plot(distributions)\n",
    "\n",
    "distributions = [(('Av. X Position', 'Av. Energy Deposited [GeV]', 'Incident energy [GeV]') , (average_x_shower, total_deposited_e_shower, all_incident_e, average_x_shower_trans, total_deposited_e_shower_trans, all_incident_e_trans))]\n",
    "util.display.make_plot(distributions)\n",
    "\n",
    "distributions = [(('Av. X Position', 'Av. Y Position', 'Incident energy [GeV]') , (average_x_shower, average_y_shower, all_incident_e, average_x_shower_trans, average_y_shower_trans, all_incident_e_trans))]\n",
    "util.display.make_plot(distributions)\n",
    "\n",
    "distributions = [(('Incident energy [GeV]', 'Av. Energy Deposited [GeV]', 'Incident energy [GeV]') , (all_incident_e, total_deposited_e_shower, all_incident_e, all_incident_e_trans, total_deposited_e_shower_trans, all_incident_e_trans))]\n",
    "util.display.make_plot(distributions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
