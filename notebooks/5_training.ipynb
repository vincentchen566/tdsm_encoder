{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd482aa1",
   "metadata": {},
   "source": [
    "# Training\n",
    "Here we provide interactive scripts, with which one can train a generative model. The script uses classes and functions used in the code that runs on condor in order to obtain the optimised model trained on the full dataset. \n",
    "We advise not to train the model on the full dataset here as it will take too long. Limit the training dataset size (e.g. use a single input file) and number of epochs and use this notebook to study e.g pre-processing, hyperparameters and diffusion techniques.\n",
    "\n",
    "First, we set the environment and the various parameters for the model, hyperparameters, diffusion equations etc. We also create instances of the stochastic differential equations, machine learning model and create a list of files we want to use as input.\n",
    "\n",
    "Important: need to set the padding value to the value used in pad_events.py script to create the padded (and transformed) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988fc9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\vince\\\\tdsm_encoder\\\\notebooks', '../', '../', '../', '../', 'C:\\\\Users\\\\vince\\\\tdsm_encoder', 'C:\\\\Users\\\\vince\\\\tdsm_encoder\\\\util', 'c:\\\\Users\\\\vince\\\\tdsm_encoder\\\\notebooks', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', '', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\vince\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\Pythonwin']\n",
      "torch version:  2.2.2+cu118\n",
      "Running on device:  cuda\n",
      "Cuda used to build pyTorch:  11.8\n",
      "Current device:  0\n",
      "Cuda arch list:  ['sm_37', 'sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90', 'compute_37']\n",
      "Working directory:  ./\n",
      "[]\n",
      "+--------------------------------+-------------------+\n",
      "|          Module name           | Parameters listed |\n",
      "+--------------------------------+-------------------+\n",
      "|           cls_token            |        512        |\n",
      "|          embed.weight          |        2048       |\n",
      "|           embed.bias           |        512        |\n",
      "|        embed_e.1.weight        |       262144      |\n",
      "|         embed_e.1.bias         |        512        |\n",
      "|        embed_t.1.weight        |       262144      |\n",
      "|         embed_t.1.bias         |        512        |\n",
      "|      dense_t.dense.weight      |        512        |\n",
      "|       dense_t.dense.bias       |         1         |\n",
      "|      dense_e.dense.weight      |        512        |\n",
      "|       dense_e.dense.bias       |         1         |\n",
      "| encoder.0.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.0.attn.in_proj_bias   |        1536       |\n",
      "| encoder.0.attn.out_proj.weight |       262144      |\n",
      "|  encoder.0.attn.out_proj.bias  |        512        |\n",
      "|  encoder.0.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.0.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.0.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.0.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.0.ffnn.0.weight     |       65536       |\n",
      "|     encoder.0.ffnn.0.bias      |        128        |\n",
      "|    encoder.0.ffnn.3.weight     |       65536       |\n",
      "|     encoder.0.ffnn.3.bias      |        512        |\n",
      "|     encoder.0.norm1.weight     |        512        |\n",
      "|      encoder.0.norm1.bias      |        512        |\n",
      "|     encoder.0.norm2.weight     |        512        |\n",
      "|      encoder.0.norm2.bias      |        512        |\n",
      "|     encoder.0.norm3.weight     |        512        |\n",
      "|      encoder.0.norm3.bias      |        512        |\n",
      "|     encoder.0.norm4.weight     |        512        |\n",
      "|      encoder.0.norm4.bias      |        512        |\n",
      "| encoder.1.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.1.attn.in_proj_bias   |        1536       |\n",
      "| encoder.1.attn.out_proj.weight |       262144      |\n",
      "|  encoder.1.attn.out_proj.bias  |        512        |\n",
      "|  encoder.1.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.1.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.1.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.1.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.1.ffnn.0.weight     |       65536       |\n",
      "|     encoder.1.ffnn.0.bias      |        128        |\n",
      "|    encoder.1.ffnn.3.weight     |       65536       |\n",
      "|     encoder.1.ffnn.3.bias      |        512        |\n",
      "|     encoder.1.norm1.weight     |        512        |\n",
      "|      encoder.1.norm1.bias      |        512        |\n",
      "|     encoder.1.norm2.weight     |        512        |\n",
      "|      encoder.1.norm2.bias      |        512        |\n",
      "|     encoder.1.norm3.weight     |        512        |\n",
      "|      encoder.1.norm3.bias      |        512        |\n",
      "|     encoder.1.norm4.weight     |        512        |\n",
      "|      encoder.1.norm4.bias      |        512        |\n",
      "| encoder.2.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.2.attn.in_proj_bias   |        1536       |\n",
      "| encoder.2.attn.out_proj.weight |       262144      |\n",
      "|  encoder.2.attn.out_proj.bias  |        512        |\n",
      "|  encoder.2.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.2.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.2.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.2.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.2.ffnn.0.weight     |       65536       |\n",
      "|     encoder.2.ffnn.0.bias      |        128        |\n",
      "|    encoder.2.ffnn.3.weight     |       65536       |\n",
      "|     encoder.2.ffnn.3.bias      |        512        |\n",
      "|     encoder.2.norm1.weight     |        512        |\n",
      "|      encoder.2.norm1.bias      |        512        |\n",
      "|     encoder.2.norm2.weight     |        512        |\n",
      "|      encoder.2.norm2.bias      |        512        |\n",
      "|     encoder.2.norm3.weight     |        512        |\n",
      "|      encoder.2.norm3.bias      |        512        |\n",
      "|     encoder.2.norm4.weight     |        512        |\n",
      "|      encoder.2.norm4.bias      |        512        |\n",
      "| encoder.3.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.3.attn.in_proj_bias   |        1536       |\n",
      "| encoder.3.attn.out_proj.weight |       262144      |\n",
      "|  encoder.3.attn.out_proj.bias  |        512        |\n",
      "|  encoder.3.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.3.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.3.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.3.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.3.ffnn.0.weight     |       65536       |\n",
      "|     encoder.3.ffnn.0.bias      |        128        |\n",
      "|    encoder.3.ffnn.3.weight     |       65536       |\n",
      "|     encoder.3.ffnn.3.bias      |        512        |\n",
      "|     encoder.3.norm1.weight     |        512        |\n",
      "|      encoder.3.norm1.bias      |        512        |\n",
      "|     encoder.3.norm2.weight     |        512        |\n",
      "|      encoder.3.norm2.bias      |        512        |\n",
      "|     encoder.3.norm3.weight     |        512        |\n",
      "|      encoder.3.norm3.bias      |        512        |\n",
      "|     encoder.3.norm4.weight     |        512        |\n",
      "|      encoder.3.norm4.bias      |        512        |\n",
      "| encoder.4.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.4.attn.in_proj_bias   |        1536       |\n",
      "| encoder.4.attn.out_proj.weight |       262144      |\n",
      "|  encoder.4.attn.out_proj.bias  |        512        |\n",
      "|  encoder.4.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.4.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.4.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.4.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.4.ffnn.0.weight     |       65536       |\n",
      "|     encoder.4.ffnn.0.bias      |        128        |\n",
      "|    encoder.4.ffnn.3.weight     |       65536       |\n",
      "|     encoder.4.ffnn.3.bias      |        512        |\n",
      "|     encoder.4.norm1.weight     |        512        |\n",
      "|      encoder.4.norm1.bias      |        512        |\n",
      "|     encoder.4.norm2.weight     |        512        |\n",
      "|      encoder.4.norm2.bias      |        512        |\n",
      "|     encoder.4.norm3.weight     |        512        |\n",
      "|      encoder.4.norm3.bias      |        512        |\n",
      "|     encoder.4.norm4.weight     |        512        |\n",
      "|      encoder.4.norm4.bias      |        512        |\n",
      "| encoder.5.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.5.attn.in_proj_bias   |        1536       |\n",
      "| encoder.5.attn.out_proj.weight |       262144      |\n",
      "|  encoder.5.attn.out_proj.bias  |        512        |\n",
      "|  encoder.5.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.5.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.5.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.5.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.5.ffnn.0.weight     |       65536       |\n",
      "|     encoder.5.ffnn.0.bias      |        128        |\n",
      "|    encoder.5.ffnn.3.weight     |       65536       |\n",
      "|     encoder.5.ffnn.3.bias      |        512        |\n",
      "|     encoder.5.norm1.weight     |        512        |\n",
      "|      encoder.5.norm1.bias      |        512        |\n",
      "|     encoder.5.norm2.weight     |        512        |\n",
      "|      encoder.5.norm2.bias      |        512        |\n",
      "|     encoder.5.norm3.weight     |        512        |\n",
      "|      encoder.5.norm3.bias      |        512        |\n",
      "|     encoder.5.norm4.weight     |        512        |\n",
      "|      encoder.5.norm4.bias      |        512        |\n",
      "| encoder.6.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.6.attn.in_proj_bias   |        1536       |\n",
      "| encoder.6.attn.out_proj.weight |       262144      |\n",
      "|  encoder.6.attn.out_proj.bias  |        512        |\n",
      "|  encoder.6.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.6.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.6.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.6.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.6.ffnn.0.weight     |       65536       |\n",
      "|     encoder.6.ffnn.0.bias      |        128        |\n",
      "|    encoder.6.ffnn.3.weight     |       65536       |\n",
      "|     encoder.6.ffnn.3.bias      |        512        |\n",
      "|     encoder.6.norm1.weight     |        512        |\n",
      "|      encoder.6.norm1.bias      |        512        |\n",
      "|     encoder.6.norm2.weight     |        512        |\n",
      "|      encoder.6.norm2.bias      |        512        |\n",
      "|     encoder.6.norm3.weight     |        512        |\n",
      "|      encoder.6.norm3.bias      |        512        |\n",
      "|     encoder.6.norm4.weight     |        512        |\n",
      "|      encoder.6.norm4.bias      |        512        |\n",
      "| encoder.7.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.7.attn.in_proj_bias   |        1536       |\n",
      "| encoder.7.attn.out_proj.weight |       262144      |\n",
      "|  encoder.7.attn.out_proj.bias  |        512        |\n",
      "|  encoder.7.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.7.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.7.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.7.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.7.ffnn.0.weight     |       65536       |\n",
      "|     encoder.7.ffnn.0.bias      |        128        |\n",
      "|    encoder.7.ffnn.3.weight     |       65536       |\n",
      "|     encoder.7.ffnn.3.bias      |        512        |\n",
      "|     encoder.7.norm1.weight     |        512        |\n",
      "|      encoder.7.norm1.bias      |        512        |\n",
      "|     encoder.7.norm2.weight     |        512        |\n",
      "|      encoder.7.norm2.bias      |        512        |\n",
      "|     encoder.7.norm3.weight     |        512        |\n",
      "|      encoder.7.norm3.bias      |        512        |\n",
      "|     encoder.7.norm4.weight     |        512        |\n",
      "|      encoder.7.norm4.bias      |        512        |\n",
      "|           out.weight           |        2048       |\n",
      "|            out.bias            |         4         |\n",
      "+--------------------------------+-------------------+\n",
      "Sum of trainable parameters: 11076614\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "import time, functools, torch, os,sys, random, fnmatch, psutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam,RAdam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from prettytable import PrettyTable\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pickle import load\n",
    "from IPython import display\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "#import trans_tdsm, utils\n",
    "import util.data_utils as utils\n",
    "import util.score_model as score_model\n",
    "import util.sdes as sdes\n",
    "import util.display\n",
    "\n",
    "# GPU device info\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:516\"\n",
    "os.system('nvidia-smi')\n",
    "\n",
    "# Set padding value used\n",
    "padding_value = 0.0\n",
    "\n",
    "dataset = \"dataset_2_padded_nentry\"\n",
    "preproc_dataset_name = 'ds2_diff_transforms'\n",
    "dataset_store_path = os.path.join(\"C:/Users/vince/tdsm_encoder/datasetstest/\", preproc_dataset_name)\n",
    "transform = None\n",
    "transform_y = None\n",
    "mask = True\n",
    "jupyternotebook = True\n",
    "workingdir = \"./\"\n",
    "\n",
    "### SDE PARAMETERS ###\n",
    "SDE = 'VP'\n",
    "if SDE == 'VP':\n",
    "    beta_max = 1.0\n",
    "    beta_min = 0.01\n",
    "if SDE == 'VE':\n",
    "    sigma_max = 20.0\n",
    "    sigma_min = 0.1\n",
    "    \n",
    "### MODEL PARAMETERS ###\n",
    "n_feat_dim = 4\n",
    "embed_dim = 512\n",
    "hidden_dim = 128\n",
    "num_encoder_blocks = 8\n",
    "num_attn_heads = 16\n",
    "dropout_gen = 0\n",
    "\n",
    "# Instantiate stochastic differential equation\n",
    "if SDE == 'VP':\n",
    "    sde = sdes.VPSDE(beta_max=beta_max,beta_min=beta_min, device=device)\n",
    "if SDE == 'VE':\n",
    "    sde = sdes.VESDE(sigma_max=sigma_max,sigma_min=sigma_min,device=device)\n",
    "marginal_prob_std_fn = functools.partial(sde.marginal_prob)\n",
    "diffusion_coeff_fn = functools.partial(sde.sde)\n",
    "\n",
    "print('torch version: ', torch.__version__)\n",
    "print('Running on device: ', device)\n",
    "if torch.cuda.is_available():\n",
    "    print('Cuda used to build pyTorch: ',torch.version.cuda)\n",
    "    print('Current device: ', torch.cuda.current_device())\n",
    "    print('Cuda arch list: ', torch.cuda.get_arch_list())\n",
    "\n",
    "print('Working directory: ', workingdir)\n",
    "\n",
    "# Input files\n",
    "files_list_ = []\n",
    "for filename in os.listdir(dataset_store_path):\n",
    "    if fnmatch.fnmatch(filename, dataset + '*424To564.pt'):\n",
    "        files_list_.append(os.path.join(dataset_store_path, filename))\n",
    "print(files_list_)\n",
    "\n",
    "# Instantiate model\n",
    "model=score_model.Gen(n_feat_dim, embed_dim, hidden_dim, num_encoder_blocks, num_attn_heads, dropout_gen, marginal_prob_std=marginal_prob_std_fn)\n",
    "torch.save(model.state_dict(), 'initial_model.pt')\n",
    "table = PrettyTable(['Module name', 'Parameters listed'])\n",
    "t_params = 0\n",
    "for name_ , para_ in model.named_parameters():\n",
    "    if not para_.requires_grad: continue\n",
    "    param = para_.numel()\n",
    "    table.add_row([name_, param])\n",
    "    t_params+=param\n",
    "print(table)\n",
    "print(f'Sum of trainable parameters: {t_params}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fe119",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The following cell will call training methods from the trans_tdsm.py script so everything should be synchronised with what we can run on condor for the big jobs.\n",
    "\n",
    "Once you have a a fully trained model you can look at the sampling notebook to see how to generate samples and make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa3b437",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m      9\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m---> 10\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[43mtrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Setup exponentially decaying learning rate\u001b[39;00m\n\u001b[0;32m     12\u001b[0m initial_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-4\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\vince\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py:312\u001b[0m, in \u001b[0;36mtnrange\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtnrange\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shortcut for `tqdm.notebook.tqdm(range(*args), **kwargs)`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtqdm_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "### HYPERPARAMETERS ###\n",
    "train_ratio = 0.8\n",
    "batch_size = 128\n",
    "n_epochs = 200\n",
    "epochs = trange(n_epochs)\n",
    "# Setup exponentially decaying learning rate\n",
    "initial_lr = 5e-4\n",
    "\n",
    "### Model ###\n",
    "model = score_model.Gen(n_feat_dim, embed_dim, hidden_dim, num_encoder_blocks, num_attn_heads, dropout_gen, marginal_prob_std=marginal_prob_std_fn)\n",
    "state_dict = torch.load('initial_model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "### optimiser ###\n",
    "optimiser = RAdam(model.parameters(),lr=initial_lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimiser, gamma=0.99)\n",
    "\n",
    "output_directory = workingdir+'/training_'+datetime.now().strftime('%Y%m%d_%H%M')+'_'+preproc_dataset_name+'/'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "av_training_losses_per_epoch = []\n",
    "av_testing_losses_per_epoch = []\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(8,4))\n",
    "dh = display.display(fig, display_id=True)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_xlabel('lr')\n",
    "ax[1].set_xlim(initial_lr*0.99**(n_epochs), initial_lr)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].tick_params('both', length=10, width=1, which='both')\n",
    "\n",
    "lrs_ = []\n",
    "\n",
    "print(files_list_)\n",
    "eps_ = []\n",
    "for epoch in epochs:\n",
    "    eps_.append(epoch)\n",
    "    # Create/clear per epoch variables\n",
    "    cumulative_epoch_loss = 0.\n",
    "    cumulative_test_epoch_loss = 0.\n",
    "\n",
    "    file_counter = 0\n",
    "    n_training_showers = 0\n",
    "    n_testing_showers = 0\n",
    "    training_batches_per_epoch = 0\n",
    "    testing_batches_per_epoch = 0\n",
    "\n",
    "    # Load files\n",
    "    for filename in files_list_:\n",
    "        custom_data = utils.cloud_dataset(filename, device=device)\n",
    "        train_size = int(train_ratio * len(custom_data.data))\n",
    "        test_size = len(custom_data.data) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(custom_data, [train_size, test_size])\n",
    "        n_training_showers+=train_size\n",
    "        n_testing_showers+=test_size\n",
    "        \n",
    "        # Load clouds for each epoch of data dataloaders length will be the number of batches\n",
    "        shower_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        shower_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Accumuate number of batches per epoch\n",
    "        training_batches_per_epoch += len(shower_loader_train)\n",
    "        testing_batches_per_epoch += len(shower_loader_test)\n",
    "\n",
    "        # Load shower batch for training\n",
    "        for i, (shower_data,incident_energies) in enumerate(shower_loader_train,0):\n",
    "            # Move model to device and set dtype as same as data (note torch.double works on both CPU and GPU)\n",
    "            model.to(device, shower_data.dtype)\n",
    "            model.train()\n",
    "            shower_data = shower_data.to(device)\n",
    "            incident_energies = incident_energies.to(device)\n",
    "\n",
    "            if len(shower_data) < 1:\n",
    "                print('Very few hits in shower: ', len(shower_data))\n",
    "                continue\n",
    "            # Zero any gradients from previous steps\n",
    "            optimiser.zero_grad()\n",
    "            # Loss average for each batch\n",
    "            loss = score_model.loss_fn(model, shower_data, incident_energies, marginal_prob_std_fn, padding_value, device=device, diffusion_on_mask=False)\n",
    "            # Accumulate batch loss per epoch\n",
    "            cumulative_epoch_loss+=float(loss)\n",
    "            # collect dL/dx for any parameters (x) which have requires_grad = True via: x.grad += dL/dx\n",
    "            loss.backward()\n",
    "            # Update value of x += -lr * x.grad\n",
    "            optimiser.step()\n",
    "\n",
    "        # Testing on subset of file\n",
    "        for i, (shower_data,incident_energies) in enumerate(shower_loader_test,0):\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                shower_data = shower_data.to(device)\n",
    "                incident_energies = incident_energies.to(device)\n",
    "                test_loss = score_model.loss_fn(model, shower_data, incident_energies, marginal_prob_std_fn, padding_value, device=device, diffusion_on_mask=False)\n",
    "                cumulative_test_epoch_loss+=float(test_loss)\n",
    "\n",
    "    # Calculate average loss per epoch\n",
    "    av_training_losses_per_epoch.append(cumulative_epoch_loss/training_batches_per_epoch)\n",
    "    av_testing_losses_per_epoch.append(cumulative_test_epoch_loss/testing_batches_per_epoch)\n",
    "    \n",
    "    lr_ = optimiser.param_groups[0]['lr']\n",
    "    epochs.set_description('Average Loss: {:5f}(Train) {:5f}(Test) {:5f}(lr)'.format(cumulative_epoch_loss/training_batches_per_epoch, cumulative_test_epoch_loss/testing_batches_per_epoch, lr_))\n",
    "    ax[0].plot(av_training_losses_per_epoch[1:], c='blue', label='training')\n",
    "    ax[0].plot(av_testing_losses_per_epoch[1:], c='red', label='testing')\n",
    "    \n",
    "    # End of epoch, change the learning rate\n",
    "    before_lr = optimiser.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    after_lr = optimiser.param_groups[0]['lr']\n",
    "    lrs_.append(before_lr)\n",
    "    ax[1].plot(lrs_[1:], av_training_losses_per_epoch[1:], c='blue')\n",
    "    if epoch == 0:\n",
    "        ax[0].legend(loc='upper right')\n",
    "    dh.update(fig)\n",
    "    if n_epochs%5 == 0:\n",
    "        torch.save(model.state_dict(), output_directory+'ckpt_tmp_'+str(epoch)+'.pth')\n",
    "    \n",
    "fig.savefig(output_directory+'loss_v_epoch.png')\n",
    "torch.save(model.state_dict(), output_directory+'ckpt_tmp_'+str(epoch)+'.pth')\n",
    "\n",
    "util.display.plot_loss_vs_epoch(eps_, av_training_losses_per_epoch, av_testing_losses_per_epoch, odir=output_directory, zoom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
